CSCI 3320 Fundamentals of Machine Learning
Course Project
Steve  - 11550, Atif Khurshid 1155085457
2. The Dataset and pre-processing
2.2 Data pre-processing
2.2.3 Indices and features for horses, jockeys and trainers
Number of horses:  2155
Number of jockeys:  105
Number of trainers:  93

Number of features is small
In general, the RBF kernel is a reasonable first choice. This kernel nonlinearly maps
samples into a higher dimensional space so it, unlike the linear kernel, can handle the
case when the relation between class labels and attributes is nonlinear. Furthermore,
the linear kernel is a special case of RBF Keerthi and Lin (2003) since the linear
kernel with a penalty parameter C˜ has the same performance as the RBF kernel with
some parameters (C, ?). In addition, the sigmoid kernel behaves like RBF for certain
parameters (Lin and Lin, 2003).
The second reason is the number of hyperparameters which influences the complexity
of model selection. The polynomial kernel has more hyperparameters than
the RBF kernel.
Finally, the RBF kernel has fewer numerical difficulties. One key point is 0 <
Kij = 1 in contrast to polynomial kernels of which kernel values may go to infinity
(?xi
T xj + r > 1) or zero (?xi
T xj + r < 1) while the degree is large. Moreover, we
must note that the sigmoid kernel is not valid (i.e. not the inner product of two
4
vectors) under some parameters (Vapnik, 1995).

model_name          RMSE   Top_1   Top_3     Average_Rank
svr_model,         1.567   0.200    0.473       4.763
Scaled svr_model,  1.591   0.223    0.494       4.515
gbrt_model,        1.568   0.229    0.490       4.510
Scaled gbrt_model, 1.567   0.229    0.492       4.502

